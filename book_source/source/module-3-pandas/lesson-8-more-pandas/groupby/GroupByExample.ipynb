{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":2,"cells":[{"cell_type":"markdown","source":["# groupby"],"metadata":{}},{"cell_type":"markdown","source":["<div style=\"position: relative; padding-bottom: 62.5%; height: 0;\">\n","    <iframe src=\"https://www.loom.com/embed/352158e95d7f49dbb1c3dcd1bea4ee71?sharedAppSource=personal_library\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%;\"></iframe>\n","</div>\n","\n","---\n","\n","```{admonition} Jupyter Notebooks\n","Reminder, that on this site the Jupyter Notebooks are read-only and you can't interact with them. Click the <i class=\"fas fa-rocket\"></i> button above to launch\n","an interactive version of this notebook.\n","\n","* With Binder, you get a temporary Jupyter Notebook website that opens with this notebook. Any code you write will be lost when you close the tab. Make sure to download the notebook so you can save it for later!\n","* With Colab, it will open Google Colaboratory. You can save the notebook there to your Google Drive. If you don't save to your Drive, any code you write will be lost when you close the tab. You can find the data files for this notebook below:\n","  * {download}`earthquakes.csv <./earthquakes.csv>`\n","\n","\n","You will need to run all the cells of the notebook to see the output. You can do this with hitting `Shift-Enter` on each cell or clickin the \"Run All\" button above.\n","```\n","\n","Think back to the list of dictionaries problem we did last week computing how \"shaky\" each location was (a made-up metric by Hunter, the wannabe seismologist). The Shake Factor for each location is just the sum of all the magnitudes of earthquakes in that location across all time.\n","\n","On your next take-home assessment, we will ask you to make computations like this (albeit for a different dataset) and we will ask you to do each problem twice: once processing the data as a list of dictionaries (like you did last week), and again using `pandas`. It is helpful to understand that the \"magic\" behind pandas is really just code like you would write for the list of dictionaries! So before showing you how to solve this problem with `pandas`, let's walk through the solution here. \n","\n","## Processing a List of Dictionaries\n","For this problem, we want to process the `earthquakes.csv` as a list of dictionaries and return the result as a dictionary (where the keys are place names and the values are ShakeFactor)."],"metadata":{},"attachments":{}},{"cell_type":"code","execution_count":5,"source":["import cse163_utils"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":6,"source":["# Using the code we wrote to parse the CSV to a list of dictionaries\n","data = cse163_utils.parse('earthquakes.csv')\n","data[:5]  # First 5 rows"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'id': 'nc72666881',\n","  'year': 2016,\n","  'month': 7,\n","  'day': 27,\n","  'latitude': 37.6723333,\n","  'longitude': -121.619,\n","  'name': 'California',\n","  'magnitude': 1.43},\n"," {'id': 'us20006i0y',\n","  'year': 2016,\n","  'month': 7,\n","  'day': 27,\n","  'latitude': 21.5146,\n","  'longitude': 94.5721,\n","  'name': 'Burma',\n","  'magnitude': 4.9},\n"," {'id': 'nc72666891',\n","  'year': 2016,\n","  'month': 7,\n","  'day': 27,\n","  'latitude': 37.5765,\n","  'longitude': -118.85916670000002,\n","  'name': 'California',\n","  'magnitude': 0.06},\n"," {'id': 'nc72666896',\n","  'year': 2016,\n","  'month': 7,\n","  'day': 27,\n","  'latitude': 37.595833299999995,\n","  'longitude': -118.99483329999998,\n","  'name': 'California',\n","  'magnitude': 0.4},\n"," {'id': 'nn00553447',\n","  'year': 2016,\n","  'month': 7,\n","  'day': 27,\n","  'latitude': 39.3775,\n","  'longitude': -119.845,\n","  'name': 'Nevada',\n","  'magnitude': 0.3}]"]},"metadata":{},"execution_count":6}],"metadata":{}},{"cell_type":"markdown","source":["So now to write the code to compute the ShakeFactor, we will follow the following workflow:\n","* Create a result dictionary\n","* Loop through the data\n","  * For each earthquake, find its magnitude and place and add the magnitude to the dictionary using the place as the key.\n"," "],"metadata":{},"attachments":{}},{"cell_type":"code","execution_count":7,"source":["shake_factors = {}  # Empty dictionary\n","for earthquake in data:\n","    place = earthquake['name']\n","    magnitude = earthquake['magnitude']\n","    shake_factors[place] += magnitude\n","\n","shake_factors"],"outputs":[{"output_type":"error","ename":"KeyError","evalue":"'California'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d0c77ffcab06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mearthquake\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmagnitude\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mearthquake\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'magnitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mshake_factors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmagnitude\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mshake_factors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'California'"]}],"metadata":{}},{"cell_type":"markdown","source":["Oops! We ran into the same error we saw earlier in the week when trying to count the number of words in a file. When you use a `dict` as a counter, you have to make sure the key is present before trying to modify its value with a `+=`. To fix this, we can add cases for whether or not we have seen this place before."],"metadata":{},"attachments":{}},{"cell_type":"code","execution_count":5,"source":["shake_factors = {}  # Empty dictionary\n","for earthquake in data:\n","    place = earthquake['name']\n","    magnitude = earthquake['magnitude']\n","    if place in shake_factors:\n","        shake_factors[place] += magnitude\n","    else:\n","        # Don't increment, just create the key/value\n","        shake_factors[place] = magnitude  \n","        \n","    # An alternative solution uses the following structure instead of the if/else\n","    # if place not in shake_facotrs:\n","    #     shake_factors[place] = 0\n","    # shake_factors[place] += magnitude\n","        \n","shake_factors"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'California': 3638.4900000000084,\n"," 'Burma': 22.200000000000003,\n"," 'Nevada': 496.6400000000006,\n"," 'Alaska': 3407.0000000000005,\n"," 'Hawaii': 375.2099999999998,\n"," 'Montana': 91.19000000000001,\n"," 'Puerto Rico': 385.99999999999983,\n"," 'Chile': 157.79999999999998,\n"," 'Dominican Republic': 97.70000000000002,\n"," 'British Virgin Islands': 230.09999999999994,\n"," 'Indonesia': 298.60000000000014,\n"," 'Washington': 176.2199999999999,\n"," 'Southern East Pacific Rise': 15.799999999999999,\n"," 'Argentina': 49.3,\n"," 'Philippines': 85.19999999999999,\n"," 'Canada': 99.96,\n"," 'Papua New Guinea': 130.3,\n"," 'Afghanistan': 43.6,\n"," 'Oregon': 107.23000000000002,\n"," 'South of Africa': 4.5,\n"," 'Peru': 63.800000000000004,\n"," 'Fiji': 75.0,\n"," 'Japan': 192.60000000000002,\n"," 'Oklahoma': 192.79999999999993,\n"," 'Mexico': 111.45,\n"," 'Kyrgyzstan': 39.8,\n"," 'Tennessee': 36.24,\n"," 'Tonga': 66.5,\n"," 'Arkansas': 6.66,\n"," 'South of the Fiji Islands': 77.00000000000001,\n"," 'Utah': 71.59,\n"," 'Georgia': 4.2,\n"," 'U.S. Virgin Islands': 84.49999999999999,\n"," 'Idaho': 27.930000000000003,\n"," 'Wyoming': 46.29999999999999,\n"," 'Iran': 13.299999999999999,\n"," 'Syria': 4.4,\n"," 'Russia': 122.60000000000001,\n"," 'Tajikistan': 53.80000000000001,\n"," 'Southwest Indian Ridge': 41.6,\n"," 'Anguilla': 2.4,\n"," 'Panama': 13.399999999999999,\n"," 'Kansas': 47.489999999999995,\n"," 'Northern Mariana Islands': 239.00000000000003,\n"," 'Christmas Island': 5.0,\n"," 'China': 63.900000000000006,\n"," 'New Zealand': 88.40000000000002,\n"," 'Vanuatu': 43.1,\n"," 'Guatemala': 26.300000000000004,\n"," 'Greece': 9.4,\n"," 'Poland': 4.2,\n"," 'Chagos Archipelago region': 4.4,\n"," 'Italy': 64.3,\n"," 'Virgin Islands region': 1.8,\n"," 'New Jersey': 2.33,\n"," 'Northern California': 2.45,\n"," 'Southern Mid-Atlantic Ridge': 13.6,\n"," 'South Sandwich Islands': 19.9,\n"," 'South Georgia and the South Sandwich Islands': 99.7,\n"," 'Northwest of Australia': 4.1,\n"," 'South Indian Ocean': 26.900000000000002,\n"," 'Solomon Islands': 45.5,\n"," 'Mid-Indian Ridge': 4.9,\n"," 'Portugal': 12.999999999999998,\n"," 'Ascension Island region': 4.7,\n"," 'Azerbaijan': 5.0,\n"," 'India': 9.3,\n"," 'Kiribati region': 4.6,\n"," 'Martinique': 4.6,\n"," 'Venezuela': 9.0,\n"," 'Bolivia': 12.9,\n"," 'Turkey': 8.0,\n"," 'Vanuatu region': 4.5,\n"," 'Missouri': 20.469999999999995,\n"," 'Guam': 9.0,\n"," 'Ohio': 1.98,\n"," 'Nicaragua': 18.5,\n"," 'East Timor': 4.5,\n"," 'Northern Mid-Atlantic Ridge': 9.899999999999999,\n"," 'Palau': 5.3,\n"," 'Colorado': 19.4,\n"," 'West Virginia': 2.31,\n"," 'New Caledonia': 157.6,\n"," 'Australia': 14.5,\n"," 'Off the coast of Oregon': 7.199999999999999,\n"," 'Virginia': 1.94,\n"," 'Costa Rica': 17.7,\n"," 'Ukraine': 4.8,\n"," 'Colombia': 8.899999999999999,\n"," 'East of the Kuril Islands': 4.7,\n"," 'Cyprus': 4.1,\n"," 'Pacific-Antarctic Ridge': 9.399999999999999,\n"," 'Uzbekistan': 4.6,\n"," 'Illinois': 7.289999999999999,\n"," 'Central Mid-Atlantic Ridge': 4.3,\n"," 'Western Indian-Antarctic Ridge': 4.5,\n"," 'Ecuador': 8.5,\n"," 'South of Panama': 4.6,\n"," 'El Salvador': 9.399999999999999,\n"," 'Western Xizang': 9.4,\n"," 'Azores-Cape St. Vincent Ridge': 4.7,\n"," 'North Carolina': 1.92,\n"," 'North of Svalbard': 5.0,\n"," 'Texas': 2.5,\n"," 'Fiji region': 14.600000000000001,\n"," 'Reykjanes Ridge': 4.5,\n"," 'Arizona': 4.39,\n"," 'Pakistan': 4.4,\n"," 'Greenland Sea': 4.5,\n"," 'New Hampshire': 1.5,\n"," 'South Georgia Island region': 86.39999999999999,\n"," 'New York': 1.48,\n"," 'Central East Pacific Rise': 4.6,\n"," 'North of Ascension Island': 9.5,\n"," 'Pennsylvania': 1.37,\n"," 'Japan region': 11.5,\n"," 'Taiwan': 4.2,\n"," 'Kuril Islands': 4.6}"]},"metadata":{},"execution_count":5}],"metadata":{}},{"cell_type":"markdown","source":["And then we are done! It looks like California ended up being the shakiest place based on the ShakeFactor!\n","\n","What we have just done is implementing what data scientists call a **group by** operation on the data. One way of describing our algorithm at a high level was we put all the earthquakes into groups based on some key (in this example, the name of the location), and then computed some **aggregate** value for each group (in this case, the aggregate value is the sum of all the magnitudes for that group). \n","\n","A group by operation is the generalization of this approach to summarizing data by some group. In general, a group by groups the data based on some attribute and then computes some value for all the values in that group. So to specify a group-by, you need to identify:\n","* How do you identify the group for a particular row? (e.g., name)\n","* How do you compute an aggregate value for all the rows in a group? What column do you use for the computation (e.g., magnitude) and how do you combine them (e.g., sum).\n","\n","\n","## Processing a `pandas` `DataFrame`\n","Now, if you were trying to do this with a list of dictionaries, you would have to write specialized code for every different type of group by you might want to try (e.g. finding the max or finding the average). However, with `pandas`, things become much simpler to write. \n","\n","Understanding how the list of dictionaries approach works is a good starting point to understand what happens in the background when using `pandas`. \n","\n","We will start by loading the data into `pandas`."],"metadata":{},"attachments":{}},{"cell_type":"code","execution_count":6,"source":["import pandas as pd"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":7,"source":["df = pd.read_csv('earthquakes.csv')\n","df"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>year</th>\n","      <th>month</th>\n","      <th>day</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","      <th>name</th>\n","      <th>magnitude</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>nc72666881</td>\n","      <td>2016</td>\n","      <td>7</td>\n","      <td>27</td>\n","      <td>37.672333</td>\n","      <td>-121.619000</td>\n","      <td>California</td>\n","      <td>1.43</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>us20006i0y</td>\n","      <td>2016</td>\n","      <td>7</td>\n","      <td>27</td>\n","      <td>21.514600</td>\n","      <td>94.572100</td>\n","      <td>Burma</td>\n","      <td>4.90</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>nc72666891</td>\n","      <td>2016</td>\n","      <td>7</td>\n","      <td>27</td>\n","      <td>37.576500</td>\n","      <td>-118.859167</td>\n","      <td>California</td>\n","      <td>0.06</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>nc72666896</td>\n","      <td>2016</td>\n","      <td>7</td>\n","      <td>27</td>\n","      <td>37.595833</td>\n","      <td>-118.994833</td>\n","      <td>California</td>\n","      <td>0.40</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>nn00553447</td>\n","      <td>2016</td>\n","      <td>7</td>\n","      <td>27</td>\n","      <td>39.377500</td>\n","      <td>-119.845000</td>\n","      <td>Nevada</td>\n","      <td>0.30</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>8389</th>\n","      <td>nc72685246</td>\n","      <td>2016</td>\n","      <td>8</td>\n","      <td>25</td>\n","      <td>36.515499</td>\n","      <td>-121.099831</td>\n","      <td>California</td>\n","      <td>2.42</td>\n","    </tr>\n","    <tr>\n","      <th>8390</th>\n","      <td>ak13879193</td>\n","      <td>2016</td>\n","      <td>8</td>\n","      <td>25</td>\n","      <td>61.498400</td>\n","      <td>-149.862700</td>\n","      <td>Alaska</td>\n","      <td>1.40</td>\n","    </tr>\n","    <tr>\n","      <th>8391</th>\n","      <td>nc72685251</td>\n","      <td>2016</td>\n","      <td>8</td>\n","      <td>25</td>\n","      <td>38.805000</td>\n","      <td>-122.821503</td>\n","      <td>California</td>\n","      <td>1.06</td>\n","    </tr>\n","    <tr>\n","      <th>8392</th>\n","      <td>ci37672328</td>\n","      <td>2016</td>\n","      <td>8</td>\n","      <td>25</td>\n","      <td>34.308000</td>\n","      <td>-118.635333</td>\n","      <td>California</td>\n","      <td>1.55</td>\n","    </tr>\n","    <tr>\n","      <th>8393</th>\n","      <td>ci37672360</td>\n","      <td>2016</td>\n","      <td>8</td>\n","      <td>25</td>\n","      <td>34.119167</td>\n","      <td>-116.933667</td>\n","      <td>California</td>\n","      <td>0.89</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8394 rows Ã— 8 columns</p>\n","</div>"],"text/plain":["              id  year  month  day   latitude   longitude        name  \\\n","0     nc72666881  2016      7   27  37.672333 -121.619000  California   \n","1     us20006i0y  2016      7   27  21.514600   94.572100       Burma   \n","2     nc72666891  2016      7   27  37.576500 -118.859167  California   \n","3     nc72666896  2016      7   27  37.595833 -118.994833  California   \n","4     nn00553447  2016      7   27  39.377500 -119.845000      Nevada   \n","...          ...   ...    ...  ...        ...         ...         ...   \n","8389  nc72685246  2016      8   25  36.515499 -121.099831  California   \n","8390  ak13879193  2016      8   25  61.498400 -149.862700      Alaska   \n","8391  nc72685251  2016      8   25  38.805000 -122.821503  California   \n","8392  ci37672328  2016      8   25  34.308000 -118.635333  California   \n","8393  ci37672360  2016      8   25  34.119167 -116.933667  California   \n","\n","      magnitude  \n","0          1.43  \n","1          4.90  \n","2          0.06  \n","3          0.40  \n","4          0.30  \n","...         ...  \n","8389       2.42  \n","8390       1.40  \n","8391       1.06  \n","8392       1.55  \n","8393       0.89  \n","\n","[8394 rows x 8 columns]"]},"metadata":{},"execution_count":7}],"metadata":{}},{"cell_type":"markdown","source":["We will first just show how to do this type of grouping operation in `pandas` and then we will walk through piece-by-piece to understand what each part of the code is doing."],"metadata":{}},{"cell_type":"code","execution_count":8,"source":["df.groupby('name')['magnitude'].sum()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["name\n","Afghanistan                         43.60\n","Alaska                            3407.00\n","Anguilla                             2.40\n","Argentina                           49.30\n","Arizona                              4.39\n","                                   ...   \n","Washington                         176.22\n","West Virginia                        2.31\n","Western Indian-Antarctic Ridge       4.50\n","Western Xizang                       9.40\n","Wyoming                             46.30\n","Name: magnitude, Length: 118, dtype: float64"]},"metadata":{},"execution_count":8}],"metadata":{}},{"cell_type":"markdown","source":["That's so much shorter to write and computes all the same values! \n","\n","The way to read this line of code uses the following logic:\n","* `df` is the `DataFrame` we want to process\n","* `.groupby('name')` tells the `DataFrame` we want it to group all of its rows based on the `name` attribute. You should think about this step as forming all the groups.\n","* `['magnitude'].sum()` at the end tells the `DataFrame` to go to each group, select the `magnitude` from all the rows in that group, and then `sum` them up.\n","\n","You aren't just restricted to using `sum`, you can use any of the `Series` methods we learned earlier like `min`, `max`, `average`. You can also group by any attribute or use any attribute for your computations!\n","\n","Interestingly enough, the final result is a `Series` that uses the place names as its index, and the values are the values computed. That means you could do something like, find the ShakeFactor for California specifically."],"metadata":{},"attachments":{}},{"cell_type":"code","execution_count":9,"source":["shake_factor_pandas = df.groupby('name')['magnitude'].sum()\n","shake_factor_pandas['California']"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["3638.4900000000084"]},"metadata":{},"execution_count":9}],"metadata":{}},{"cell_type":"markdown","source":["## What's going on here?\n","It's pretty incredible that such a short line of code can do something so complex. In the bullet-list above, I described the steps that happen here but I find it easier to think about it with a small example. The figure below shows a visual explanation of what is going on when you do a `groupby`.\n","1. (Teal, `data`) You start by specifying `DataFrame` you want to do this computation on\n","2. (Purple, `.groupby('col1')`) You then call the `groupby` function on that `DataFrame` passing as a parameter the column that will form the groups. This splits the data up into groups based on the provided column.\n","    * Notice this does NOT use the `[]` notation! This is not accessing a column of the `DataFrame`, but rather is calling a function passing a parameter\n","3. (Red, `['col2'].sum()`) Specify which column we want to aggregate (e.g., `col2`) and what function we should use to make the aggregate (e.g. `.sum()`). The turns each group into a single value.\n","    * Notice in this part we DO use the `[]` notation since we are accessing a particular column\n","4. (Green, `result = `) The return value of this call is a `Series` that has the index being the keys defining the groups and values being the aggregate value for that group.\n","\n","![Groupby Diagram](img/groupby.png \"Image showing a visual representation of the data being split up and aggregated as described above\")\n","\n","To get a better idea of this, let's explore the return of the `groupby` without doing step 3 of specifying an aggregate."],"metadata":{},"attachments":{}},{"cell_type":"code","execution_count":10,"source":["# Make a DataFrame by giving it a list of dictionaries\n","example_data = pd.DataFrame([\n","    {'col1': 'A', 'col2': 1},\n","    {'col1': 'B', 'col2': 2},\n","    {'col1': 'C', 'col2': 3},\n","    {'col1': 'A', 'col2': 4},\n","    {'col1': 'C', 'col2': 5},\n","])\n","\n","example_data"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>col1</th>\n","      <th>col2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>B</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>C</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>A</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>C</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  col1  col2\n","0    A     1\n","1    B     2\n","2    C     3\n","3    A     4\n","4    C     5"]},"metadata":{},"execution_count":10}],"metadata":{}},{"cell_type":"code","execution_count":11,"source":["groupby = example_data.groupby('col1') # Notice no aggregate\n","groupby"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f0a79ff2bb0>"]},"metadata":{},"execution_count":11}],"metadata":{}},{"cell_type":"markdown","source":["This returns a special `pandas` object called a `DataFrameGroupBy`. This represents an \"unfinished\" `groupby` operation since we have not computed an aggregate yet. One feature that is kind of helpful for seeing what's going on (but you will probably rarely use in practice) is the fact you can loop over a `DataFrameGroupBy` to inspect the groups."],"metadata":{},"attachments":{}},{"cell_type":"code","execution_count":12,"source":["for key, group in groupby: \n","    print('==== Next Group: ' + str(key) + ' ====')\n","    display(group) # To get the fancy Jupyter Notebook display of table"],"outputs":[{"output_type":"stream","name":"stdout","text":["==== Next Group: A ====\n"]},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>col1</th>\n","      <th>col2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>A</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  col1  col2\n","0    A     1\n","3    A     4"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["==== Next Group: B ====\n"]},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>col1</th>\n","      <th>col2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>B</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  col1  col2\n","1    B     2"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["==== Next Group: C ====\n"]},{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>col1</th>\n","      <th>col2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>C</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>C</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  col1  col2\n","2    C     3\n","4    C     5"]},"metadata":{}}],"metadata":{}},{"cell_type":"markdown","source":["This is why when we do finish the computation, we get the sum of all these rows that fell into each group"],"metadata":{},"attachments":{}},{"cell_type":"code","execution_count":13,"source":["result = example_data.groupby('col1')['col2'].sum()\n","result"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["col1\n","A    5\n","B    2\n","C    8\n","Name: col2, dtype: int64"]},"metadata":{},"execution_count":13}],"metadata":{}},{"cell_type":"markdown","source":["Again, it's important to highlight that **`result` is a `Series` that has indices equal to the group keys**. You can see in the cell below we print out its type and show how to access a particular value. We also show how you can view the indices of a `Series` (also works for `DataFrames`)."],"metadata":{},"attachments":{}},{"cell_type":"code","execution_count":14,"source":["print(type(result))\n","print(result.index)\n","print(result['C'])"],"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.series.Series'>\n","Index(['A', 'B', 'C'], dtype='object', name='col1')\n","8\n"]}],"metadata":{}},{"cell_type":"markdown","source":["## When to use this?\n","Whenever you want to separate your data into groups to get some value for each one, this is the natural time to ues a `groupby`! Whenever you see \"for each\" or \"per\" in a question, it's likely you will want to use a `groupby`. \n","\n","Here are some example questions you can solve with a groupby. We provide some \"code\" to compute each one, assuming the data had columns with the relevant names.\n","* Compute the number of students per section\n","    ```\n","    grades.groupby('Section')['StudentID'].count()\n","    ```\n","* Compute the average grade of students in each section\n","    ```\n","    grades.groupby('Section')['Grade'].mean()\n","    ```\n","* Compute the total number of people in each country\n","    ```\n","    cities.groupby('country')['population'].sum()\n","    ```"],"metadata":{},"attachments":{}}]}