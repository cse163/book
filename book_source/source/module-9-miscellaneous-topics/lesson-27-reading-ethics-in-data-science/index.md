# <i class="fas fa-book fa-fw"></i> Lesson 27 Reading: Ethics in Data Science

We will discuss ethics in data science. Since this is not a philosophy class, we are not quite able to discuss frameworks of ethics or define a bunch of terms (although they are essential, they aren't our expertise). Instead, we will focus on studying ways data science can go wrong as a series of case studies. These case studies aren't comprehensive of all ways data science can go wrong, but can hopefully act as reference points or reminders when exploring your applications.

In this reading, we will talk about 5 applications of data science.

- A "gaydar" that predicts sexual orientation from a picture of someone's face

- Uber's "Rides of Glory" blog post

- Using machine learning to help with prison sentencing

- Automatically detecting potholes in a city.

- Facial Recognition

This reading is a bit longer, but the goal here is to have a wider breadth of examples for you to draw from in your future careers. You do not need to understand every single detail from each example, but you should at least look over them all to understand the key take-away. Your responsibility at the end of this reading is to make a post sharing an opinion on a discussion board thread so you shouldn't feel overwhelmed by all the small details presented.

```{admonition} Note
:class: note

There are no recordings of Hunter for this lesson, to give you more time to process what you are reading since it can be a

```

## Table of Contents

```{toctree}
:maxdepth: 1
:caption: Contents

case-study-0-predicting-crime
case-study-1-rides-of-glory
case-study-2-compas
case-study-3-potholes-in-baltimore
case-study-4-facial-recognition
wrap-up-and-assignment
```
